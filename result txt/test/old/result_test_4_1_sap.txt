/opt/conda/lib/python3.12/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import ZeroRedundancyOptimizer
2025-10-13 12:40:13,991 ignite.distributed.launcher.Parallel INFO: - Run '<function training at 0x76e92948e0c0>' in 1 processes
2025-10-13 12:40:14,077 ALCD_CLOUD INFO: Train ags_tiny_unet_50k on CIFAR10
2025-10-13 12:40:14,078 ALCD_CLOUD INFO: - PyTorch version: 2.4.1+cu121
2025-10-13 12:40:14,078 ALCD_CLOUD INFO: - Ignite version: 0.5.1
2025-10-13 12:40:14,096 ALCD_CLOUD INFO: - GPU Device: NVIDIA GeForce RTX 3090
2025-10-13 12:40:14,096 ALCD_CLOUD INFO: - CUDA version: 12.1
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: - CUDNN version: 90100
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 

2025-10-13 12:40:14,097 ALCD_CLOUD INFO: Configuration:
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	seed: 23456
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	data_path: /pvc/
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	csv_paths: {'train': '/pvc/1_new_sap/train_noisy.csv', 'test': '/pvc/1_new_sap/test_noisy.csv'}
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	output_path: ./output-alcd-cloud-noisy/
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	input_size: (512, 512)
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	img_mean: [0.0, 0.0, 0.0]
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	img_rescale: [8657.0, 8657.0, 8657.0]
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	model: ags_tiny_unet_50k
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	quant_config: 4
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	class_weights: [0.1, 0.9]
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	batch_size: 28
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	weight_decay: 0.0002
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	num_workers: 8
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	num_epochs: 2
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	learning_rate: 0.001
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	num_warmup_epochs: 1
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	validate_every: 3
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	checkpoint_every: 1000
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	backend: None
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	resume_from: /pvc/output-alcd-cloud-4-new-saveall/best_checkpoint_93_test_F1=0.8458.pt
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	log_every_iters: 5
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	nproc_per_node: None
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	stop_iteration: None
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 	with_amp: False
2025-10-13 12:40:14,097 ALCD_CLOUD INFO: 

2025-10-13 12:40:14,097 ALCD_CLOUD INFO: Output path: output-alcd-cloud-noisy/ags_tiny_unet_50k_backend-None-1_20251013-124014
2025-10-13 12:40:14,395 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<utils.utils.ALCDDat': 
	{'batch_size': 28, 'num_workers': 8, 'shuffle': True, 'drop_last': True, 'pin_memory': True}
/opt/conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2025-10-13 12:40:14,395 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset '<utils.utils.ALCDDat': 
	{'batch_size': 56, 'num_workers': 8, 'shuffle': False, 'pin_memory': True}
2025-10-13 12:40:14,770 ALCD_CLOUD INFO: Resuming from checkpoint: /pvc/output-alcd-cloud-4-new-saveall/best_checkpoint_93_test_F1=0.8458.pt
/SCRIPTS/test_new.py:437: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(checkpoint_fp.as_posix(), map_location="cpu")
2025-10-13 12:40:14,845 ALCD_CLOUD WARNING: Missing keys: ['input_quant.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc1.block1.depthwise.weight', 'enc1.block1.pointwise.weight', 'enc1.block1.pointwise.bias', 'enc1.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc1.block2.depthwise.weight', 'enc1.block2.pointwise.weight', 'enc1.block2.pointwise.bias', 'enc1.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc2.block1.depthwise.weight', 'enc2.block1.pointwise.weight', 'enc2.block1.pointwise.bias', 'enc2.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc2.block2.depthwise.weight', 'enc2.block2.pointwise.weight', 'enc2.block2.pointwise.bias', 'enc2.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc3.block1.depthwise.weight', 'enc3.block1.pointwise.weight', 'enc3.block1.pointwise.bias', 'enc3.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc3.block2.depthwise.weight', 'enc3.block2.pointwise.weight', 'enc3.block2.pointwise.bias', 'enc3.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc4.block1.depthwise.weight', 'enc4.block1.pointwise.weight', 'enc4.block1.pointwise.bias', 'enc4.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc4.block2.depthwise.weight', 'enc4.block2.pointwise.weight', 'enc4.block2.pointwise.bias', 'enc4.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc_middle.block1.depthwise.weight', 'enc_middle.block1.pointwise.weight', 'enc_middle.block1.pointwise.bias', 'enc_middle.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'enc_middle.block2.depthwise.weight', 'enc_middle.block2.pointwise.weight', 'enc_middle.block2.pointwise.bias', 'enc_middle.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec_middle.block1.depthwise.weight', 'dec_middle.block1.pointwise.weight', 'dec_middle.block1.pointwise.bias', 'dec_middle.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec_middle.block2.depthwise.weight', 'dec_middle.block2.pointwise.weight', 'dec_middle.block2.pointwise.bias', 'dec_middle.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec1.block1.depthwise.weight', 'dec1.block1.pointwise.weight', 'dec1.block1.pointwise.bias', 'dec1.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec1.block2.depthwise.weight', 'dec1.block2.pointwise.weight', 'dec1.block2.pointwise.bias', 'dec1.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec2.block1.depthwise.weight', 'dec2.block1.pointwise.weight', 'dec2.block1.pointwise.bias', 'dec2.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec2.block2.depthwise.weight', 'dec2.block2.pointwise.weight', 'dec2.block2.pointwise.bias', 'dec2.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec3.block1.depthwise.weight', 'dec3.block1.pointwise.weight', 'dec3.block1.pointwise.bias', 'dec3.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec3.block2.depthwise.weight', 'dec3.block2.pointwise.weight', 'dec3.block2.pointwise.bias', 'dec3.block2.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec4.block1.depthwise.weight', 'dec4.block1.pointwise.weight', 'dec4.block1.pointwise.bias', 'dec4.block1.act.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value', 'dec4.block2.depthwise.weight', 'dec4.block2.pointwise.weight', 'dec4.block2.pointwise.bias'], Unexpected keys: ['model', 'trainer', 'optimizer', 'lr_scheduler']
start train test
done get train test datasets
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/rasterio/__init__.py:356: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
/opt/conda/lib/python3.12/site-packages/torch/_tensor.py:1413: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1925.)
  return super().rename(names)
/opt/conda/lib/python3.12/site-packages/torch/nn/modules/conv.py:454: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:294.)
  return F.conv2d(input, weight, bias, self.stride,
2025-10-13 12:41:50,075 ALCD_CLOUD INFO: Epoch[0] - Evaluation time (seconds): 95.149
 - Test metrics:
 	Precision: tensor([0.0000, 0.2343], dtype=torch.float64)
	Recall: tensor([0., 1.], dtype=torch.float64)
	F1: tensor([0.0000, 0.3796], dtype=torch.float64)
	Loss: 0.8228224907112905
2025-10-13 12:41:50,076 ignite.distributed.launcher.Parallel INFO: End of run
